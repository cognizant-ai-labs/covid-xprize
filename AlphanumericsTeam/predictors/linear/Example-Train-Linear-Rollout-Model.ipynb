{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Copyright 2020 (c) Cognizant Digital Business, Evolutionary AI. All rights reserved. Issued under the Apache 2.0 License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Predictor: Linear Rollout Predictor\n",
    "\n",
    "This example contains basic functionality for training and evaluating a linear predictor that rolls out predictions day-by-day.\n",
    "\n",
    "First, a training data set is created from historical case and npi data.\n",
    "\n",
    "Second, a linear model is trained to predict future cases from prior case data along with prior and future npi data.\n",
    "The model is an off-the-shelf sklearn Lasso model, that uses a positive weight constraint to enforce the assumption that increased npis has a negative correlation with future cases.\n",
    "\n",
    "Third, a sample evaluation set is created, and the predictor is applied to this evaluation set to produce prediction results in the correct format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AlphanumericsTeam.data.util import get_aug_oxford_df, filter_df_regions\n",
    "\n",
    "# Has 6 additional columns \n",
    "# 'New Cases' \n",
    "# 'GeoID' \n",
    "# 'Holidays' \n",
    "# 'pop_2020' \n",
    "# 'area_km2' \n",
    "# 'density_perkm2'\n",
    "df = get_aug_oxford_df() \n",
    "df = filter_df_regions(df)\n",
    "assert df.CountryName.unique().size == 180\n",
    "assert df.RegionName.unique().size == 56 + 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       CountryName CountryCode RegionName RegionCode Jurisdiction       Date  \\\n",
       "92           Aruba         ABW                   NaN    NAT_TOTAL 2020-04-01   \n",
       "93           Aruba         ABW                   NaN    NAT_TOTAL 2020-04-02   \n",
       "94           Aruba         ABW                   NaN    NAT_TOTAL 2020-04-03   \n",
       "95           Aruba         ABW                   NaN    NAT_TOTAL 2020-04-04   \n",
       "96           Aruba         ABW                   NaN    NAT_TOTAL 2020-04-05   \n",
       "...            ...         ...        ...        ...          ...        ...   \n",
       "183263    Zimbabwe         ZWE                   NaN    NAT_TOTAL 2020-12-14   \n",
       "183264    Zimbabwe         ZWE                   NaN    NAT_TOTAL 2020-12-15   \n",
       "183265    Zimbabwe         ZWE                   NaN    NAT_TOTAL 2020-12-16   \n",
       "183266    Zimbabwe         ZWE                   NaN    NAT_TOTAL 2020-12-17   \n",
       "183267    Zimbabwe         ZWE                   NaN    NAT_TOTAL 2020-12-18   \n",
       "\n",
       "        C1_School closing  C1_Flag  C2_Workplace closing  C2_Flag  ...  \\\n",
       "92                    3.0      1.0                   3.0      1.0  ...   \n",
       "93                    3.0      1.0                   3.0      1.0  ...   \n",
       "94                    3.0      1.0                   3.0      1.0  ...   \n",
       "95                    3.0      1.0                   3.0      1.0  ...   \n",
       "96                    3.0      1.0                   3.0      1.0  ...   \n",
       "...                   ...      ...                   ...      ...  ...   \n",
       "183263                NaN      NaN                   NaN      NaN  ...   \n",
       "183264                NaN      NaN                   NaN      NaN  ...   \n",
       "183265                NaN      NaN                   NaN      NaN  ...   \n",
       "183266                NaN      NaN                   NaN      NaN  ...   \n",
       "183267                NaN      NaN                   NaN      NaN  ...   \n",
       "\n",
       "        ContainmentHealthIndex  ContainmentHealthIndexForDisplay  \\\n",
       "92                       65.38                             65.38   \n",
       "93                       65.38                             65.38   \n",
       "94                       65.38                             65.38   \n",
       "95                       65.38                             65.38   \n",
       "96                       65.38                             65.38   \n",
       "...                        ...                               ...   \n",
       "183263                     NaN                             60.26   \n",
       "183264                     NaN                             60.26   \n",
       "183265                     NaN                             60.26   \n",
       "183266                     NaN                             60.26   \n",
       "183267                     NaN                             60.26   \n",
       "\n",
       "        EconomicSupportIndex  EconomicSupportIndexForDisplay  NewCases  \\\n",
       "92                      87.5                            87.5       0.0   \n",
       "93                      87.5                            87.5       5.0   \n",
       "94                      87.5                            87.5       2.0   \n",
       "95                      87.5                            87.5       2.0   \n",
       "96                      87.5                            87.5       0.0   \n",
       "...                      ...                             ...       ...   \n",
       "183263                   NaN                            25.0     112.0   \n",
       "183264                   NaN                            25.0     164.0   \n",
       "183265                   NaN                            25.0     227.0   \n",
       "183266                   NaN                            25.0       0.0   \n",
       "183267                   NaN                            25.0       0.0   \n",
       "\n",
       "             GeoID  Holidays    pop_2020  area_km2  density_perkm2  \n",
       "92         Aruba__       0.0    106766.0     180.0          593.14  \n",
       "93         Aruba__       0.0    106766.0     180.0          593.14  \n",
       "94         Aruba__       0.0    106766.0     180.0          593.14  \n",
       "95         Aruba__       1.0    106766.0     180.0          593.14  \n",
       "96         Aruba__       1.0    106766.0     180.0          593.14  \n",
       "...            ...       ...         ...       ...             ...  \n",
       "183263  Zimbabwe__       0.0  14862924.0  390757.0              38  \n",
       "183264  Zimbabwe__       0.0  14862924.0  390757.0              38  \n",
       "183265  Zimbabwe__       0.0  14862924.0  390757.0              38  \n",
       "183266  Zimbabwe__       0.0  14862924.0  390757.0              38  \n",
       "183267  Zimbabwe__       0.0  14862924.0  390757.0              38  \n",
       "\n",
       "[124372 rows x 55 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CountryName</th>\n      <th>CountryCode</th>\n      <th>RegionName</th>\n      <th>RegionCode</th>\n      <th>Jurisdiction</th>\n      <th>Date</th>\n      <th>C1_School closing</th>\n      <th>C1_Flag</th>\n      <th>C2_Workplace closing</th>\n      <th>C2_Flag</th>\n      <th>...</th>\n      <th>ContainmentHealthIndex</th>\n      <th>ContainmentHealthIndexForDisplay</th>\n      <th>EconomicSupportIndex</th>\n      <th>EconomicSupportIndexForDisplay</th>\n      <th>NewCases</th>\n      <th>GeoID</th>\n      <th>Holidays</th>\n      <th>pop_2020</th>\n      <th>area_km2</th>\n      <th>density_perkm2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>92</th>\n      <td>Aruba</td>\n      <td>ABW</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NAT_TOTAL</td>\n      <td>2020-04-01</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>65.38</td>\n      <td>65.38</td>\n      <td>87.5</td>\n      <td>87.5</td>\n      <td>0.0</td>\n      <td>Aruba__</td>\n      <td>0.0</td>\n      <td>106766.0</td>\n      <td>180.0</td>\n      <td>593.14</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>Aruba</td>\n      <td>ABW</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NAT_TOTAL</td>\n      <td>2020-04-02</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>65.38</td>\n      <td>65.38</td>\n      <td>87.5</td>\n      <td>87.5</td>\n      <td>5.0</td>\n      <td>Aruba__</td>\n      <td>0.0</td>\n      <td>106766.0</td>\n      <td>180.0</td>\n      <td>593.14</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>Aruba</td>\n      <td>ABW</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NAT_TOTAL</td>\n      <td>2020-04-03</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>65.38</td>\n      <td>65.38</td>\n      <td>87.5</td>\n      <td>87.5</td>\n      <td>2.0</td>\n      <td>Aruba__</td>\n      <td>0.0</td>\n      <td>106766.0</td>\n      <td>180.0</td>\n      <td>593.14</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>Aruba</td>\n      <td>ABW</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NAT_TOTAL</td>\n      <td>2020-04-04</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>65.38</td>\n      <td>65.38</td>\n      <td>87.5</td>\n      <td>87.5</td>\n      <td>2.0</td>\n      <td>Aruba__</td>\n      <td>1.0</td>\n      <td>106766.0</td>\n      <td>180.0</td>\n      <td>593.14</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Aruba</td>\n      <td>ABW</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NAT_TOTAL</td>\n      <td>2020-04-05</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>65.38</td>\n      <td>65.38</td>\n      <td>87.5</td>\n      <td>87.5</td>\n      <td>0.0</td>\n      <td>Aruba__</td>\n      <td>1.0</td>\n      <td>106766.0</td>\n      <td>180.0</td>\n      <td>593.14</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>183263</th>\n      <td>Zimbabwe</td>\n      <td>ZWE</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NAT_TOTAL</td>\n      <td>2020-12-14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>60.26</td>\n      <td>NaN</td>\n      <td>25.0</td>\n      <td>112.0</td>\n      <td>Zimbabwe__</td>\n      <td>0.0</td>\n      <td>14862924.0</td>\n      <td>390757.0</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>183264</th>\n      <td>Zimbabwe</td>\n      <td>ZWE</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NAT_TOTAL</td>\n      <td>2020-12-15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>60.26</td>\n      <td>NaN</td>\n      <td>25.0</td>\n      <td>164.0</td>\n      <td>Zimbabwe__</td>\n      <td>0.0</td>\n      <td>14862924.0</td>\n      <td>390757.0</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>183265</th>\n      <td>Zimbabwe</td>\n      <td>ZWE</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NAT_TOTAL</td>\n      <td>2020-12-16</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>60.26</td>\n      <td>NaN</td>\n      <td>25.0</td>\n      <td>227.0</td>\n      <td>Zimbabwe__</td>\n      <td>0.0</td>\n      <td>14862924.0</td>\n      <td>390757.0</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>183266</th>\n      <td>Zimbabwe</td>\n      <td>ZWE</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NAT_TOTAL</td>\n      <td>2020-12-17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>60.26</td>\n      <td>NaN</td>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>Zimbabwe__</td>\n      <td>0.0</td>\n      <td>14862924.0</td>\n      <td>390757.0</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>183267</th>\n      <td>Zimbabwe</td>\n      <td>ZWE</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NAT_TOTAL</td>\n      <td>2020-12-18</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>60.26</td>\n      <td>NaN</td>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>Zimbabwe__</td>\n      <td>0.0</td>\n      <td>14862924.0</td>\n      <td>390757.0</td>\n      <td>38</td>\n    </tr>\n  </tbody>\n</table>\n<p>124372 rows Ã— 55 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# For testing, restrict training data to that before a hypothetical predictor submission date\n",
    "HYPOTHETICAL_SUBMISSION_DATE = np.datetime64(\"today\")\n",
    "TRAINING_START_DATE = np.datetime64(\"2020-04-01\" )\n",
    "df = df[(TRAINING_START_DATE<=df.Date) & (df.Date<= HYPOTHETICAL_SUBMISSION_DATE)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only columns of interest\n",
    "id_cols = ['CountryName',\n",
    "           'RegionName',\n",
    "           'GeoID',\n",
    "           'Date']\n",
    "cases_col = ['NewCases']\n",
    "npi_cols = ['C1_School closing',\n",
    "            'C2_Workplace closing',\n",
    "            'C3_Cancel public events',\n",
    "            'C4_Restrictions on gatherings',\n",
    "            'C5_Close public transport',\n",
    "            'C6_Stay at home requirements',\n",
    "            'C7_Restrictions on internal movement',\n",
    "            'C8_International travel controls',\n",
    "            'H1_Public information campaigns',\n",
    "            'H2_Testing policy',\n",
    "            'H3_Contact tracing',\n",
    "            'H6_Facial Coverings']\n",
    "new_features = ['Holidays'\n",
    "                ]\n",
    "df = df[id_cols + cases_col + npi_cols + new_features] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "92        0.000000\n",
       "93        1.609438\n",
       "94        0.693147\n",
       "95        0.693147\n",
       "96        0.000000\n",
       "            ...   \n",
       "183263    4.718499\n",
       "183264    5.099866\n",
       "183265    5.424950\n",
       "183266    0.000000\n",
       "183267    0.000000\n",
       "Name: LogNewCases, Length: 124372, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df[df[\"NewCases\"]<=0] = 1\n",
    "df[\"LogNewCases\"] = np.log(df[\"NewCases\"])\n",
    "df[\"LogNewCases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill any missing case values by interpolation and setting NaNs to 0\n",
    "df.update(df.groupby('GeoID').NewCases.apply(\n",
    "    lambda group: group.interpolate()).fillna(0))\n",
    "\n",
    "# Fill any missing NPIs by assuming they are the same as previous day\n",
    "for npi_col in npi_cols:\n",
    "    df.update(df.groupby('GeoID')[npi_col].ffill().fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['CountryName', 'RegionName', 'GeoID', 'Date', 'NewCases',\n",
       "       'C1_School closing', 'C2_Workplace closing', 'C3_Cancel public events',\n",
       "       'C4_Restrictions on gatherings', 'C5_Close public transport',\n",
       "       'C6_Stay at home requirements', 'C7_Restrictions on internal movement',\n",
       "       'C8_International travel controls', 'H1_Public information campaigns',\n",
       "       'H2_Testing policy', 'H3_Contact tracing', 'H6_Facial Coverings',\n",
       "       'Holidays', 'LogNewCases'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(524,) 39.0 5348.0\n[0.71856793 0.82959948 1.42535805 0.93140827 0.72987004 1.14470294\n 0.96123702 0.58810259 1.20914239 1.43708642] 0.16289259247507343 7.161148740394319\n[131.28692325 160.02489866 463.41910882 215.12249345 118.98443104\n 274.90134225 178.30872225  54.28523318 218.93096483 328.86443528] 1.0 27947.0704608495\n[-0.33049503 -0.18681225  0.35442305 -0.07105757 -0.31488878  0.13514516\n -0.03953426 -0.53085387  0.18991134  0.36261775] -1.8146642372437034 1.9686704067062166\n[ 94.33857261 132.75657242 660.53815711 200.3668697   86.84317185\n 314.68037549 171.39694478  31.92528648 264.7187098  472.60661542] 1.0 200133.1284284237\n"
     ]
    }
   ],
   "source": [
    "from AlphanumericsTeam.predictors.tools.exp_fit import get_exp_fit\n",
    "nb_lookback_days = 3\n",
    "gdf = df[df.GeoID == \"United States__Alabama\"] \n",
    "all_case_data = np.squeeze(np.array(gdf[cases_col]) )\n",
    "print( all_case_data.shape, np.min(all_case_data), np.max(all_case_data))\n",
    "\n",
    "Rt, A, Lambda ,ExpFit  = get_exp_fit(all_case_data, nb_lookback_days, 1)\n",
    "#print(gdf)\n",
    "print(Rt[10:20], np.min(Rt), np.max(Rt))\n",
    "print(A[10:20], np.min(A), np.max(A))\n",
    "print(Lambda[10:20], np.min(Lambda), np.max(Lambda))\n",
    "print(ExpFit[10:20], np.min(ExpFit), np.max(ExpFit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set number of past days to use to make predictions\n",
    "nb_lookback_days = 7\n",
    "\n",
    "# Create training data across all countries for predicting one day ahead\n",
    "X_cols = cases_col + npi_cols\n",
    "y_col = cases_col\n",
    "X_samples = []\n",
    "y_samples = []\n",
    "geo_ids = df.GeoID.unique()\n",
    "for g in geo_ids:\n",
    "    gdf = df[df.GeoID == g]\n",
    "    all_case_data = np.array(gdf[cases_col])\n",
    "    all_npi_data = np.array(gdf[npi_cols])\n",
    "    all_feat_data = np.array(gdf[new_features])\n",
    "\n",
    "    # Create one sample for each day where we have enough data\n",
    "    # Each sample consists of cases and npis for previous nb_lookback_days\n",
    "    nb_total_days = len(gdf)\n",
    "    for d in range(nb_lookback_days, nb_total_days - 1):\n",
    "        X_cases = all_case_data[d-nb_lookback_days:d]\n",
    "\n",
    "        # Take negative of npis to support positive\n",
    "        # weight constraint in Lasso.\n",
    "        X_npis = -all_npi_data[d - nb_lookback_days:d]\n",
    "\n",
    "        X_feats = all_feat_data[d - nb_lookback_days:d]\n",
    "\n",
    "        # Flatten all input data so it fits Lasso input format.\n",
    "        X_sample = np.concatenate([X_cases.flatten(),\n",
    "                                   X_npis.flatten(),\n",
    "                                   X_feats.flatten()])\n",
    "                                   \n",
    "        y_sample = all_case_data[d]\n",
    "        X_samples.append(X_sample)\n",
    "        y_samples.append(y_sample)\n",
    "\n",
    "X_samples = np.array(X_samples)\n",
    "y_samples = np.array(y_samples).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(122482, 98)\n(122482,)\n"
     ]
    }
   ],
   "source": [
    "print(X_samples.shape)\n",
    "print(y_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful function to compute mae\n",
    "def mae(pred, true):\n",
    "    return np.mean(np.abs(pred - true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_samples,\n",
    "                                                    y_samples,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, max_iter=10000, positive=True, precompute=True,\n",
       "      selection='random')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Create and train Lasso model.\n",
    "# Set positive=True to enforce assumption that cases are positively correlated\n",
    "# with future cases and npis are negatively correlated.\n",
    "model = Lasso(alpha=0.1,\n",
    "              precompute=True,\n",
    "              max_iter=10000,\n",
    "              positive=True,\n",
    "              selection='random')\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train MAE: 377.3451003985817\nTest MAE: 384.88543678674023\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "train_preds = model.predict(X_train)\n",
    "train_preds = np.maximum(train_preds, 0) # Don't predict negative cases\n",
    "print('Train MAE:', mae(train_preds, y_train))\n",
    "\n",
    "test_preds = model.predict(X_test)\n",
    "test_preds = np.maximum(test_preds, 0) # Don't predict negative cases\n",
    "print('Test MAE:', mae(test_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Day -7 NewCases 0.07639677043473975\nDay -6 NewCases 0.06038552960529926\nDay -5 NewCases 0.2803740504202994\nDay -4 NewCases 0.05254730085470343\nDay -3 NewCases 0.04797148303872078\nDay -2 NewCases 0.4135238168103157\nDay -1 NewCases 0.06505683335297956\nDay -7 C6_Stay at home requirements 2.887834461571283\nDay -7 C8_International travel controls 17.16082414522693\nDay -6 C6_Stay at home requirements 9.51519817202433\nDay 0 C1_School closing 68.2749113413561\nDay 0 C3_Cancel public events 8.606317269862253e-05\nDay 0 C6_Stay at home requirements 0.0003024128042793258\nDay 0 H1_Public information campaigns 0.0021905117228077473\nDay 0 H6_Facial Coverings 0.0002800765552415766\nDay -7 Holidays 24.377009551176883\nDay -7 density_perkm2 0.0002007922417092906\nDay -6 Holidays 9.850256928272572\nDay -6 density_perkm2 0.0008647302861244309\nDay -5 Holidays 230.51354384817876\nDay -5 density_perkm2 0.00015959388981122872\nIntercept 217.43187563476658\n"
     ]
    }
   ],
   "source": [
    "# Inspect the learned feature coefficients for the model\n",
    "# to see what features it's paying attention to.\n",
    "\n",
    "# Give names to the features\n",
    "x_col_names = []\n",
    "for d in range(-nb_lookback_days, 0):\n",
    "    x_col_names.append('Day ' + str(d) + ' ' + cases_col[0])\n",
    "for d in range(-nb_lookback_days, 1):\n",
    "    for col_name in npi_cols:\n",
    "        x_col_names.append('Day ' + str(d) + ' ' + col_name)\n",
    "for d in range(-nb_lookback_days, 1):\n",
    "    for col_name in new_features:\n",
    "        x_col_names.append('Day ' + str(d) + ' ' + col_name)\n",
    "\n",
    "# View non-zero coefficients\n",
    "for (col, coeff) in zip(x_col_names, list(model.coef_)):\n",
    "    if coeff != 0.:\n",
    "        print(col, coeff)\n",
    "print('Intercept', model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to file\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "with open('models/model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now that the predictor has been trained and saved, this section contains the functionality for evaluating it on sample evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the module to get the latest changes\n",
    "import predict\n",
    "from importlib import reload\n",
    "reload(predict)\n",
    "from predict import predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds_df = predict_df(\"2020-08-01\", \"2020-08-31\", path_to_ips_file=\"../../validation/data/2020-09-30_historical_ip.csv\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the predictions\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "This is how the predictor is going to be called during the competition.  \n",
    "!!! PLEASE DO NOT CHANGE THE API !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python predict.py -s 2020-08-01 -e 2020-08-04 -ip ../../validation/data/2020-09-30_historical_ip.csv -o predictions/2020-08-01_2020-08-04.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head predictions/2020-08-01_2020-08-04.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test cases\n",
    "We can generate a prediction file. Let's validate a few cases..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from covid_xprize.validation.predictor_validation import validate_submission\n",
    "\n",
    "def validate(start_date, end_date, ip_file, output_file):\n",
    "    # First, delete any potential old file\n",
    "    try:\n",
    "        os.remove(output_file)\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "    # Then generate the prediction, calling the official API\n",
    "    !python predict.py -s {start_date} -e {end_date} -ip {ip_file} -o {output_file}\n",
    "    \n",
    "    # And validate it\n",
    "    errors = validate_submission(start_date, end_date, ip_file, output_file)\n",
    "    if errors:\n",
    "        for error in errors:\n",
    "            print(error)\n",
    "    else:\n",
    "        print(\"All good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 days, no gap\n",
    "- All countries and regions\n",
    "- Official number of cases is known up to start_date\n",
    "- Intervention Plans are the official ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(start_date=\"2020-08-01\",\n",
    "         end_date=\"2020-08-04\",\n",
    "         ip_file=\"../../validation/data/2020-09-30_historical_ip.csv\",\n",
    "         output_file=\"predictions/val_4_days.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 month in the future\n",
    "- 2 countries only\n",
    "- there's a gap between date of last known number of cases and start_date\n",
    "- For future dates, Intervention Plans contains scenarios for which predictions are requested to answer the question: what will happen if we apply these plans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(start_date=\"2021-01-01\",\n",
    "         end_date=\"2021-01-31\",\n",
    "         ip_file=\"../../validation/data/future_ip.csv\",\n",
    "         output_file=\"predictions/val_1_month_future.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 180 days, from a future date, all countries and regions\n",
    "- Prediction start date is 1 week from now. (i.e. assuming submission date is 1 week from now)  \n",
    "- Prediction end date is 6 months after start date.  \n",
    "- Prediction is requested for all available countries and regions.  \n",
    "- Intervention plan scenario: freeze last known intervention plans for each country and region.  \n",
    "\n",
    "As the number of cases is not known yet between today and start date, but the model relies on them, the model has to predict them in order to use them.  \n",
    "This test is the most demanding test. It should take less than 1 hour to generate the prediction file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = datetime.now() + timedelta(days=7)\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date = start_date + timedelta(days=180)\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "print(f\"Start date: {start_date_str}\")\n",
    "print(f\"End date: {end_date_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from covid_xprize.validation.scenario_generator import get_raw_data, generate_scenario, NPI_COLUMNS\n",
    "DATA_FILE = 'data/OxCGRT_latest.csv'\n",
    "latest_df = get_raw_data(DATA_FILE, latest=True)\n",
    "scenario_df = generate_scenario(start_date_str, end_date_str, latest_df, countries=None, scenario=\"Freeze\")\n",
    "scenario_file = \"predictions/180_days_future_scenario.csv\"\n",
    "scenario_df.to_csv(scenario_file, index=False)\n",
    "print(f\"Saved scenario to {scenario_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(start_date=start_date_str,\n",
    "         end_date=end_date_str,\n",
    "         ip_file=scenario_file,\n",
    "         output_file=\"predictions/val_6_month_future.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "72aa7907e726e8d04d999f945f887f230d22f05df97d1530ec2e882e4a50e7ee"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "# Copyright 2020 (c) Cognizant Digital Business, Evolutionary AI. All rights reserved. Issued under the Apache 2.0 License."
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}