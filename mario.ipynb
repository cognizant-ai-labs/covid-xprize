{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow a machine learning approach as exemplified in the original github.com package. Nonetheless, the initial experimentation was performed using time series algorithms as autoregressive integrated moving average (ARIMA) and autoregressive moving average (ARMA). However, the package used to create these models could not produce a model for each Country, and particular transformations were needed for each case to obtain a satisfactory ARIMA or ARMA model; given the amount of work, we decided to abandon this path and go straight to the approach described in the package examples, particular in the linear one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation\n",
    "\n",
    "The first step was to transform the data into the format required by most algorithms implemented in the scikit-learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "from EvoMSA import base\n",
    "# NixtamalAI's packages\n",
    "from covid_xprize.nixtamalai.helpers import ID_COLS\n",
    "from covid_xprize.nixtamalai import helpers\n",
    "from covid_xprize.nixtamalai import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting de data\n",
    "data = helpers.preprocess_full()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the performance of the two versions of the number of cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = {k:v for k, v in data.groupby(\"GeoID\").Population.last().items()}\n",
    "\n",
    "def predict(data, trans, model, start_date=\"2020-11-13\", end_date=\"2020-12-05\"):\n",
    "    output = defaultdict(list)\n",
    "    for X in trans.transform(data, start=start_date, end=end_date):\n",
    "        hy = trans.update_prediction(model.predict(X))\n",
    "        key = X.iloc[0][\"GeoID\"]\n",
    "        output[key].append(hy)\n",
    "    geo_pred_dfs = list()\n",
    "    start_date = pd.to_datetime(start_date, format='%Y-%m-%d')\n",
    "    end_date = pd.to_datetime(end_date, format='%Y-%m-%d')    \n",
    "    data = data[(data.Date >= start_date) & (data.Date <= end_date)].copy()\n",
    "    for key, value in output.items():\n",
    "        geo_pred_df = data.loc[data.GeoID == key, ID_COLS].copy()\n",
    "        # print(len(value), geo_pred_df.shape, key)\n",
    "        geo_pred_df['PredictedDailyNewCases'] = value[-geo_pred_df.shape[0]:]\n",
    "        geo_pred_dfs.append(geo_pred_df)\n",
    "    pred_df = pd.concat(geo_pred_dfs)\n",
    "    return pred_df\n",
    "\n",
    "def performance(output):\n",
    "    res = pd.merge(data, output, how=\"inner\")\n",
    "    y = res.NewCasesHampel.rolling(7, min_periods=1).mean()\n",
    "    hy = res.PredictedDailyNewCases.rolling(7, min_periods=1).mean()\n",
    "    mae = metrics.mean_absolute_error(y, hy)\n",
    "\n",
    "    _ = [((100000 * value.NewCasesHampel /  population[key]).rolling(7, min_periods=1).mean().to_numpy(),\n",
    "          (100000 * value.PredictedDailyNewCases /  population[key]).rolling(7, min_periods=1).mean().to_numpy())\n",
    "         for key, value in res.groupby(\"GeoID\")]\n",
    "\n",
    "    y = np.concatenate([x[0] for x in _])\n",
    "    hy = np.concatenate([x[1] for x in _])\n",
    "    return [mae, metrics.mean_absolute_error(y, hy)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is a matrix of the exogenous variables and the number of cases, each using thirty lags. Regarding the number of cases, we observed two approaches: to use the raw number, and the other is to transform it into cases per 100,000 individuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of cases\n",
    "trans = models.Features(static_cols=[]).fit(data)\n",
    "# Number of cases per 100000\n",
    "transN = models.FeaturesN(static_cols=[]).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the models\n",
    "HY = []\n",
    "for t in [trans, transN]:\n",
    "    X, y = t.training_set()\n",
    "    m = models.AR().fit(X, y)\n",
    "    _ = predict(data, t, m)\n",
    "    HY.append(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance MAE [Number of cases, Number of cases per 100000]\n",
    "for hy in HY:\n",
    "    _ = performance(hy)\n",
    "    print([\"%0.4f\" %x for x in _])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of the number of lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions when the number of lags are varied from:\n",
    "lags = [2, 4, 8, 16, 32, 64]\n",
    "HY = []\n",
    "for lag in tqdm(lags):\n",
    "    transN = models.FeaturesN(lags=lag, static_cols=[]).fit(data)\n",
    "    X, y = transN.training_set()\n",
    "    m = models.AR().fit(X, y)\n",
    "    _ = predict(data, transN, m)\n",
    "    HY.append(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = []\n",
    "for hy in HY:\n",
    "    D.append({k: v for k, v in zip([\"MAE\", \"Norm. MAE\"], performance(hy))})\n",
    "perf = pd.DataFrame(D, index=lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf.loc[:, \"Norm. MAE\"].plot(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf.loc[:, \"MAE\"].plot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between using static variables or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transN = models.FeaturesN(lags=16, static_cols=[]).fit(data)\n",
    "X, y = transN.training_set()\n",
    "m = models.AR().fit(X, y)\n",
    "_ = predict(data, transN, m)\n",
    "print(X.shape)\n",
    "performance(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transN = models.FeaturesN(lags=16).fit(data)\n",
    "X, y = transN.training_set()\n",
    "m = models.AR().fit(X, y)\n",
    "_ = predict(data, transN, m)\n",
    "print(X.shape)\n",
    "performance(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lars\n",
    "m = models.Lars().fit(X, y)\n",
    "_ = predict(data, transN, m)\n",
    "performance(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Lasso\n",
    "m = models.Lasso().fit(X, y)\n",
    "_ = predict(data, transN, m)\n",
    "performance(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EvoMSA\n",
    "evo = base.EvoMSA(TR=False, stacked_method=models.AR,\n",
    "                  classifier=False,\n",
    "                  models=[[models.Identity, models.AR],\n",
    "                          [models.Identity, models.Lars],\n",
    "                          [models.Identity, models.Lasso]]).fit(X, y)\n",
    "_ = predict(data, transN, evo)\n",
    "performance(_)                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c6e4d5b4d6d22eee4e40482a27a6c1842268e976bd336046cc4dcfdff6e20424"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
