{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor submission\n",
    "\n",
    "\n",
    "The COVID-19 crisis is proving to be one of the world’s most critical challenges — a challenge bigger than any one government or organization can tackle on its own. Right now, countries around the world are not equipped to implement health and safety interventions and policies that effectively protect both their citizens and economies.\n",
    " \n",
    "In order to fight this pandemic, we need access to localized, data-driven planning systems and the latest in artificial intelligence (AI) to help decision-makers develop and implement robust Intervention Plans (IPs) that successfully reduce infection cases and minimize economic impact.\n",
    "\n",
    "**Intervention Plan (IP)**: A plan of action or schedule for setting and resetting various intervention policies at various strengths or stringency.\n",
    "\n",
    "**Predictor Model**: Given a time sequence of IPs in effect, and other data like a time sequence of number of cases, a predictor model will estimate the number of cases in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An intervention plan consists of a set of [containment and closure policies](https://github.com/OxCGRT/covid-policy-tracker/blob/master/documentation/codebook.md#containment-and-closure-policies), as well as [health system policies](https://github.com/OxCGRT/covid-policy-tracker/blob/master/documentation/codebook.md#health-system-policies). Checkout the links to understand what these policies correspond to and how they are coded.\n",
    "\n",
    "For instance the **C1_School closing** policy, which records closings of schools and universities, is coded like that:\n",
    "\n",
    "| Code      | Meaning     |\n",
    "| :-------- | :---------- |\n",
    "|  0        | no measures |\n",
    "|  1        | recommend closing|\n",
    "|  2        | require closing (only some levels or categories, eg just high school, or just public schools) |\n",
    "|  3        | require closing all levels |\n",
    "| Blank     | no data |\n",
    "\n",
    "Interventions plans are recorded daily for each countries and sometimes for regions. For this competition, the following policies are considered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP_COLUMNS = ['C1_School closing',\n",
    "              'C2_Workplace closing',\n",
    "              'C3_Cancel public events',\n",
    "              'C4_Restrictions on gatherings',\n",
    "              'C5_Close public transport',\n",
    "              'C6_Stay at home requirements',\n",
    "              'C7_Restrictions on internal movement',\n",
    "              'C8_International travel controls',\n",
    "              'H1_Public information campaigns',\n",
    "              'H2_Testing policy',\n",
    "              'H3_Contact tracing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "The university of Oxford Blavatnik School of Government is [tracking coronavirus government responses](https://www.bsg.ox.ac.uk/research/research-projects/coronavirus-government-response-tracker). They have assembled a [data set](https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv) containing historical data since January 1st, 2020 for the number of cases and IPs for most countries in the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv'\n",
    "df = pd.read_csv(DATA_URL,\n",
    "                 parse_dates=['Date'],\n",
    "                 encoding=\"ISO-8859-1\",\n",
    "                 error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing the number of cases and IPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CASES_COLUMNS = [\"CountryName\", \"RegionName\", \"Date\", \"ConfirmedCases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[CASES_COLUMNS + IP_COLUMNS].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the daily change in cases\n",
    "The **ConfirmedCases** column reports the total number of cases since the beginning of the epidemic for each country, region and day. From this number we can compute the daily change in confirmed cases by doing:\n",
    "\n",
    "\\begin{equation*}\n",
    "DailyChangeConfirmedCases_t = ConfirmedCases_t - ConfirmedCases_{t-1}\n",
    "\\end{equation*}\n",
    "\n",
    "Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DailyChangeConfirmedCases\"] = df.groupby([\"CountryName\", \"RegionName\"]).ConfirmedCases.diff().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing the latest historical daily new cases for a given country and region\n",
    "For instance, for country **United States**, region **California**, the latest available changes in confirmed cases are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"United States\"\n",
    "region = \"California\"\n",
    "country_region_df = df[(df.CountryName == country) & (df.RegionName == region)]\n",
    "country_region_df[[\"CountryName\", \"RegionName\", \"Date\", \"ConfirmedCases\", \"DailyChangeConfirmedCases\"]].tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor input\n",
    "The goal of a predictor is to predict the expected number of daily cases for countries and regions for a list of days, assumging the given daily IPs are in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_INPUT_FILE = \"validation/data/2020-08-01_2020-08-04_ip.csv\"\n",
    "prediction_input_df = pd.read_csv(EXAMPLE_INPUT_FILE,\n",
    "                                  parse_dates=['Date'],\n",
    "                                  encoding=\"ISO-8859-1\")\n",
    "prediction_input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor expected output\n",
    "The output produced by the predictor should look like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_OUTPUT_FILE = \"2020-08-01_2020-08-04_predictions_example.csv\"\n",
    "prediction_output_df = pd.read_csv(EXAMPLE_OUTPUT_FILE,\n",
    "                                   parse_dates=['Date'],\n",
    "                                   encoding=\"ISO-8859-1\")\n",
    "prediction_output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "Train a predictor model that can produce the output file given the input file.\n",
    "\n",
    "Use additional data source if needed.\n",
    "\n",
    "Predictors do not have to predict for all regions. They can ignore them and return a row in the csv file only for regions for which they want to make a prediction. Note that a predictor submission can consist of multiple models, for example those specializing in different regions, that are accessed through the same call. A predictor must return a prediction in less than 30 seconds per region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's a good idea to save the trained model so it can be used to make predictions in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For examples, check out the examples folder:\n",
    "# - examples/zero/Example-ZeroPredictor.ipynb\n",
    "# - examples/linear/Example-Train-Linear-Model.ipynb\n",
    "# - examples/lstm/Example-LSTM-Predicxtor.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "Making predictions means saving a .csv file called \"start_date_end_date.csv\" to the root folder.\n",
    "For instance, if:\n",
    "\n",
    "```\n",
    "start_date = \"2020-08-01\"\n",
    "end_date = \"2020-08-04\"\n",
    "```\n",
    "\n",
    "Then the expected output file is **2020-08-01_2020-08-04.csv**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(start_date: str, end_date: str, path_to_ips_file: str):\n",
    "    \"\"\"\n",
    "    Generates a file with daily new cases predictions for the given countries, regions and npis, between\n",
    "    start_date and end_date, included.\n",
    "    :param start_date: day from which to start making predictions, as a string, format YYYY-MM-DDD\n",
    "    :param end_date: day on which to stop making predictions, as a string, format YYYY-MM-DDD\n",
    "    :param path_to_ips_file: path to a csv file containing the intervention plans between start_date and end_date\n",
    "    :return: Nothing. Saves a csv file called 'start_date_end_date.csv'\n",
    "    with columns \"CountryName,RegionName,Date,PredictedDailyNewCases\"\n",
    "    \"\"\"\n",
    "    output_file_name = start_date + \"_\" + end_date + \".csv\"\n",
    "    # WRITE YOUR CODE HERE\n",
    "    # Save output to path_to_output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2020-08-01\"\n",
    "end_date = \"2020-08-04\"\n",
    "predict(start_date, end_date, EXAMPLE_INPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If prediction worked ok, it generated the following file:\n",
    "output_file = start_date + \"_\" + end_date + \".csv\"\n",
    "# That we can readd like this:\n",
    "prediction_output_df = pd.read_csv(output_file,\n",
    "                                   parse_dates=['Date'],\n",
    "                                   encoding=\"ISO-8859-1\")\n",
    "prediction_output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Update `predict.py` to call the trained predictor and generate a predictor file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "This is how the predictor is going to be called during the competition.  \n",
    "!!! PLEASE DO NOT CHANGE THE API !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python predict.py -s 2020-08-01 -e 2020-08-04 -ip ../../validation/data/2020-08-01_2020-08-04_ip.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the pediction file is valid\n",
    "from validation.validation import validate_submission\n",
    "\n",
    "errors = validate_submission(\"2020-08-01\", \"2020-08-04\", \"2020-08-01_2020-08-04.csv\")\n",
    "if errors:\n",
    "    for error in errors:\n",
    "        print(error)\n",
    "else:\n",
    "    print(\"All good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python predict.py -s 2020-08-01 -e 2020-08-31 -ip ../../validation/data/2020-08-01_2020-08-31_ip.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the pediction file is valid\n",
    "errors = validate_submission(\"2020-08-01\", \"2020-08-31\", \"2020-08-01_2020-08-31.csv\")\n",
    "if errors:\n",
    "    for error in errors:\n",
    "        print(error)\n",
    "else:\n",
    "    print(\"All good!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "# Copyright 2020 (c) Cognizant Digital Business, Evolutionary AI. All rights reserved. Issued under the Apache 2.0 License."
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}